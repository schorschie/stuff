{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa65d747",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28dd3506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dict(path_json):\n",
    "    \"\"\"Write the keywords to a json file\n",
    "    \n",
    "    Using this approach I don't have to upload data base schema information to github.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    data_schema = {'histogram_column' : 'source column name',\n",
    "                   'lable_suffix' : 'suffix',\n",
    "                   'lable' : 'target column name',\n",
    "                   'table' : 'field_data',\n",
    "                   'factor' : 1,\n",
    "                   'bin_start' : 0,\n",
    "                   'bin_end' : 10,\n",
    "                   'bin_count' : 10,\n",
    "                   'where': 'lala > 0',\n",
    "                   'save_as': 'my_hist.sql'}\n",
    "    \n",
    "    with open(path_json, 'w') as f:\n",
    "        f.write(json.dumps(data_schema))\n",
    "    \n",
    "    return None\n",
    "                \n",
    "\n",
    "def create_sql_histogram(data_schema):\n",
    "    \"\"\"Read the data base schema information from json and create sql_query\"\"\"\n",
    "    \n",
    "    bins = np.linspace(data_schema['bin_start'], \n",
    "                       data_schema['bin_end'],\n",
    "                       num=data_schema['bin_count'],\n",
    "                       endpoint=True)\n",
    "    \n",
    "    sql_query = ''\n",
    "    for idx, _ in enumerate(bins[0:-1]):\n",
    "        if idx == (len(bins) - 2):\n",
    "            union = 'ORDER BY idx;'\n",
    "        else:\n",
    "            union = 'UNION'\n",
    "            \n",
    "        sql_query = \"\"\"%sSELECT\n",
    "    '%.2f to %.2f %s' AS Bucket,\n",
    "    %d AS idx,\n",
    "    COUNT(%s) * %.15f AS \"%s\"\n",
    "FROM %s\n",
    "WHERE %s BETWEEN %f AND %f\n",
    "%s\n",
    "%s\n",
    "\"\"\" % (sql_query,\n",
    "       bins[idx],\n",
    "       bins[idx+1],\n",
    "       data_schema['lable_suffix'],\n",
    "       idx,\n",
    "       data_schema['histogram_column'],\n",
    "       data_schema['factor'],\n",
    "       data_schema['lable'],\n",
    "       data_schema['table'],\n",
    "       data_schema['histogram_column'],\n",
    "       bins[idx],\n",
    "       bins[idx+1],\n",
    "       data_schema['where'],\n",
    "       union) \n",
    "        \n",
    "        \n",
    "    return sql_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe6a101d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT\n",
      "    '0.00 to 5.00 kph' AS Bucket,\n",
      "    0 AS idx,\n",
      "    COUNT(epsabsmaxvehspd) * 0.000002777777777 AS \"Duration [h]\"\n",
      "FROM field_data\n",
      "WHERE epsabsmaxvehspd BETWEEN 0.000000 AND 5.000000\n",
      "\n",
      "UNION\n",
      "SELECT\n",
      "    '5.00 to 10.00 kph' AS Bucket,\n",
      "    1 AS idx,\n",
      "    COUNT(epsabsmaxvehspd) * 0.000002777777777 AS \"Duration [h]\"\n",
      "FROM field_data\n",
      "WHERE epsabsmaxvehspd BETWEEN 5.000000 AND 10.000000\n",
      "\n",
      "UNION\n",
      "SELECT\n",
      "    '10.00 to 15.00 kph' AS Bucket,\n",
      "    2 AS idx,\n",
      "    COUNT(epsabsmaxvehspd) * 0.000002777777777 AS \"Duration [h]\"\n",
      "FROM field_data\n",
      "WHERE epsabsmaxvehspd BETWEEN 10.000000 AND 15.000000\n",
      "\n",
      "UNION\n",
      "SELECT\n",
      "    '15.00 to 20.00 kph' AS Bucket,\n",
      "    3 AS idx,\n",
      "    COUNT(epsabsmaxvehspd) * 0.000002777777777 AS \"Duration [h]\"\n",
      "FROM field_data\n",
      "WHERE epsabsmaxvehspd BETWEEN 15.000000 AND 20.000000\n",
      "\n",
      "UNION\n",
      "SELECT\n",
      "    '20.00 to 25.00 kph' AS Bucket,\n",
      "    4 AS idx,\n",
      "    COUNT(epsabsmaxvehspd) * 0.000002777777777 AS \"Duration [h]\"\n",
      "FROM field_data\n",
      "WHERE epsabsmaxvehspd BETWEEN 20.000000 AND 25.000000\n",
      "\n",
      "UNION\n",
      "SELECT\n",
      "    '25.00 to 30.00 kph' AS Bucket,\n",
      "    5 AS idx,\n",
      "    COUNT(epsabsmaxvehspd) * 0.000002777777777 AS \"Duration [h]\"\n",
      "FROM field_data\n",
      "WHERE epsabsmaxvehspd BETWEEN 25.000000 AND 30.000000\n",
      "\n",
      "UNION\n",
      "SELECT\n",
      "    '30.00 to 35.00 kph' AS Bucket,\n",
      "    6 AS idx,\n",
      "    COUNT(epsabsmaxvehspd) * 0.000002777777777 AS \"Duration [h]\"\n",
      "FROM field_data\n",
      "WHERE epsabsmaxvehspd BETWEEN 30.000000 AND 35.000000\n",
      "\n",
      "UNION\n",
      "SELECT\n",
      "    '35.00 to 40.00 kph' AS Bucket,\n",
      "    7 AS idx,\n",
      "    COUNT(epsabsmaxvehspd) * 0.000002777777777 AS \"Duration [h]\"\n",
      "FROM field_data\n",
      "WHERE epsabsmaxvehspd BETWEEN 35.000000 AND 40.000000\n",
      "\n",
      "UNION\n",
      "SELECT\n",
      "    '40.00 to 45.00 kph' AS Bucket,\n",
      "    8 AS idx,\n",
      "    COUNT(epsabsmaxvehspd) * 0.000002777777777 AS \"Duration [h]\"\n",
      "FROM field_data\n",
      "WHERE epsabsmaxvehspd BETWEEN 40.000000 AND 45.000000\n",
      "\n",
      "UNION\n",
      "SELECT\n",
      "    '45.00 to 50.00 kph' AS Bucket,\n",
      "    9 AS idx,\n",
      "    COUNT(epsabsmaxvehspd) * 0.000002777777777 AS \"Duration [h]\"\n",
      "FROM field_data\n",
      "WHERE epsabsmaxvehspd BETWEEN 45.000000 AND 50.000000\n",
      "\n",
      "UNION\n",
      "SELECT\n",
      "    '50.00 to 55.00 kph' AS Bucket,\n",
      "    10 AS idx,\n",
      "    COUNT(epsabsmaxvehspd) * 0.000002777777777 AS \"Duration [h]\"\n",
      "FROM field_data\n",
      "WHERE epsabsmaxvehspd BETWEEN 50.000000 AND 55.000000\n",
      "\n",
      "UNION\n",
      "SELECT\n",
      "    '55.00 to 60.00 kph' AS Bucket,\n",
      "    11 AS idx,\n",
      "    COUNT(epsabsmaxvehspd) * 0.000002777777777 AS \"Duration [h]\"\n",
      "FROM field_data\n",
      "WHERE epsabsmaxvehspd BETWEEN 55.000000 AND 60.000000\n",
      "\n",
      "UNION\n",
      "SELECT\n",
      "    '60.00 to 65.00 kph' AS Bucket,\n",
      "    12 AS idx,\n",
      "    COUNT(epsabsmaxvehspd) * 0.000002777777777 AS \"Duration [h]\"\n",
      "FROM field_data\n",
      "WHERE epsabsmaxvehspd BETWEEN 60.000000 AND 65.000000\n",
      "\n",
      "UNION\n",
      "SELECT\n",
      "    '65.00 to 70.00 kph' AS Bucket,\n",
      "    13 AS idx,\n",
      "    COUNT(epsabsmaxvehspd) * 0.000002777777777 AS \"Duration [h]\"\n",
      "FROM field_data\n",
      "WHERE epsabsmaxvehspd BETWEEN 65.000000 AND 70.000000\n",
      "\n",
      "UNION\n",
      "SELECT\n",
      "    '70.00 to 75.00 kph' AS Bucket,\n",
      "    14 AS idx,\n",
      "    COUNT(epsabsmaxvehspd) * 0.000002777777777 AS \"Duration [h]\"\n",
      "FROM field_data\n",
      "WHERE epsabsmaxvehspd BETWEEN 70.000000 AND 75.000000\n",
      "\n",
      "UNION\n",
      "SELECT\n",
      "    '75.00 to 80.00 kph' AS Bucket,\n",
      "    15 AS idx,\n",
      "    COUNT(epsabsmaxvehspd) * 0.000002777777777 AS \"Duration [h]\"\n",
      "FROM field_data\n",
      "WHERE epsabsmaxvehspd BETWEEN 75.000000 AND 80.000000\n",
      "\n",
      "ORDER BY idx;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('vehicle_speed.json', 'r') as f:\n",
    "    data_schema = json.load(f)\n",
    "\n",
    "my_query = create_sql_histogram(data_schema)\n",
    "\n",
    "print(my_query)\n",
    "\n",
    "with open(data_schema['save_as'], 'w') as f:\n",
    "    f.write(my_query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "deb4792152b8b9767403eeef0a1b0f34b83d442136ccee9184cd7d1131f09aa0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
